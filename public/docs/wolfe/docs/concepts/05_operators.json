{
  "name" : "Operators",
  "cells" : [ {
    "id" : 4,
    "compiler" : "markdown",
    "input" : {
      "code" : "The previous sections have shown how Scala and Wolfe can be used\nto develop the building blocks of machine learning models. \nTo do inference and learning with such models we require mathematical operators\nthat interfact with the building blocks we introduced earlier. \n\nMost wolfe operators have the form\n$$\n\\DeclareMathOperator{\\operator}{operator}\n\\operator\\_{s \\in \\mathcal{S}: c(s) } f(s)\n$$\nwhere \\\\(\\mathcal{S}\\\\) is a collection of possible worlds, \\\\(c(\\cdot)\\\\)\na constraint on possible worlds, and \\\\(f\\\\) a scalar function. \nThe previous sections have shown how these components can be implemented,\nnow we can put them together. You may test this in the examples below\nby replacing `def` with `val` definitions.\n\n\n",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 7,
    "compiler" : "heading3",
    "input" : {
      "code" : "Restrictions",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 8,
    "compiler" : "markdown",
    "input" : {
      "code" : "When models interact with operators the __restrictions of Wolfe__ with respect\nto possible worlds, constraints and functions will become apparent. While you can \nuse any Scala expression to define these building blocks, only for a subset \nof these Wolfe operators can be implemented efficiently. This is partly \nbecause the internal matching algorithms lack coverage, and partly because\nthey are certainly models for which there simply is not effective algorithm, even\nif they can be matched. At least for the coverage problem we hope to continuously\nimprove Wolfe. Moreover, Wolfe attempts to yield errors and warnings whenever building blocks are used\nthat cannot be optimized.  \n\nOne restriction is that collections of possible worlds, if not atomic, need to be defined\nusing `def` and not `val` (or used inline directly when the operator is called).\nIf `val` is used the collection effectively becomes atomic, and a lot of optimizations\ncannot be performed. \n\n",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 0,
    "compiler" : "heading3",
    "input" : {
      "code" : "Argmax",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 5,
    "compiler" : "markdown",
    "input" : {
      "code" : "Finding the argument that maximizes a function under some constraint is a fundamental \nproblem of machine learning and beyond. Wolfe currently performs two types of optimizations\ndepending on the type of search space.\n\n",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 9,
    "compiler" : "heading4",
    "input" : {
      "code" : "Discrete",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 10,
    "compiler" : "markdown",
    "input" : {
      "code" : "Discrete optimization can be used for *maximum-a-priori* (MAP) inference: finding the most likely\nor highest scoring structure given some observation and a model. \n\nIn Wolfe discrete optimization is performed whenever the search space is not a vector space.\nIn particular, even if the search space has continuous components discrete optimization is performed\nas long as the continuous components are observed. \n\nInternally Wolfe performs discrete optimization (and other operations on discrete\nspaces) by first creating a [factor graph](http://en.wikipedia.org/wiki/Factor_graph)\nrepresentation, and then running MAP inference code on this graph. In some sense\nthis process is an implementation detail that should be hidden from the user,\nin particular because it may change over time. However, without understanding\nthis process users may not understand why some models are slow and others aren't.\nWe hence aim at describing the process in more detail in the future.\n\nThe example below shows a simple application of the `argmax` operator. The operator\ntakes as first argument a search space, in this case `worlds where (_.smokesAnn)`. \nThis space is already constrained using the filter `_.smokesAnn` which is a \nScala short form of `w => w.smokesAnn`. Wolfe analyzes the syntax tree of the\n`worlds where (_.smokesAnn)` expression, translates it into a factor graph with two\nboolean variables (corresponding to `smokesAnn` and `smokesBob`), and sets the variable for\n`smokesAnn` to `true` based on the constraint `_.smokesAnn`.  \n",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 6,
    "compiler" : "wolfe",
    "input" : {
      "code" : "case class World(smokesAnn:Boolean, smokesBob:Boolean)\ndef worlds = all(World) {bools x bools}\nargmax(worlds where (_.smokesAnn)) {w => I(w.smokesAnn == w.smokesBob)}",
      "outputFormat" : "wolfe",
      "extraFields" : null
    }
  }, {
    "id" : 1,
    "compiler" : "heading3",
    "input" : {
      "code" : "Sum",
      "outputFormat" : "html",
      "extraFields" : null
    }
  }, {
    "id" : 3,
    "compiler" : "markdown",
    "input" : {
      "code" : "Blah",
      "outputFormat" : "html",
      "extraFields" : null
    }
  } ]
}
